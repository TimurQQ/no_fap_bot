import boto3
import os
import json
import zipfile
import tempfile
from datetime import datetime
from botocore.exceptions import ClientError, NoCredentialsError
from config.config import S3_ENABLED, S3_BUCKET_NAME, S3_ACCESS_KEY, S3_SECRET_KEY, S3_REGION, S3_ENDPOINT
from logger import noFapLogger


class S3BackupManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤ S3."""
    
    def __init__(self):
        self.enabled = S3_ENABLED
        self.bucket_name = S3_BUCKET_NAME
        self.s3_client = None
        
        if self.enabled:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ S3_ENDPOINT –∑–∞–¥–∞–Ω
                if not S3_ENDPOINT:
                    raise ValueError(
                        "S3_ENDPOINT is required but not set in .env file. "
                        "Please set S3_ENDPOINT to your S3-compatible storage endpoint "
                        "(e.g., https://storage.yandexcloud.net for Yandex Cloud)"
                    )
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–¥–∞–Ω–Ω—ã–π endpoint
                endpoint_url = S3_ENDPOINT
                noFapLogger.info(f"Using S3 endpoint: {endpoint_url}")
                
                self.s3_client = boto3.client(
                    's3',
                    aws_access_key_id=S3_ACCESS_KEY,
                    aws_secret_access_key=S3_SECRET_KEY,
                    region_name=S3_REGION,
                    endpoint_url=endpoint_url
                )
                noFapLogger.info("S3 backup manager initialized successfully")
            except ValueError:
                # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º ValueError (–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ S3_ENDPOINT) –¥–∞–ª—å—à–µ
                raise
            except Exception as e:
                noFapLogger.error(f"Failed to initialize S3 client: {e}")
                self.enabled = False
    
    def upload_database_backup(self, database_file_path: str) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤ S3.
        
        Args:
            database_file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            
        Returns:
            bool: True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        if not self.enabled:
            noFapLogger.warning("S3 backup is disabled, skipping upload")
            return False
            
        if not os.path.exists(database_file_path):
            noFapLogger.error(f"Database file not found: {database_file_path}")
            return False
            
        try:
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            s3_key = f"database_backups/all_scores_saved_{timestamp}.json"
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –≤ S3
            self.s3_client.upload_file(
                database_file_path,
                self.bucket_name,
                s3_key
            )
            
            noFapLogger.info(f"Database backup uploaded successfully to S3: {s3_key}")
            
            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ latest backup
            latest_key = "database_backups/all_scores_saved_latest.json"
            self.s3_client.upload_file(
                database_file_path,
                self.bucket_name,
                latest_key
            )
            
            noFapLogger.info(f"Latest backup updated: {latest_key}")
            return True
            
        except FileNotFoundError:
            noFapLogger.error(f"Database file not found: {database_file_path}")
            return False
            
        except NoCredentialsError:
            noFapLogger.error("S3 credentials not found or invalid")
            return False
            
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'NoSuchBucket':
                noFapLogger.error(f"S3 bucket '{self.bucket_name}' does not exist")
            elif error_code == 'AccessDenied':
                noFapLogger.error("Access denied to S3 bucket - check permissions")
            else:
                noFapLogger.error(f"S3 ClientError: {e}")
            return False
            
        except Exception as e:
            noFapLogger.error(f"Unexpected error during S3 upload: {e}")
            return False
    
    def download_latest_backup(self, download_path: str) -> dict:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π –±—ç–∫–∞–ø –∏–∑ S3 —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ä–µ–≤–∏–∑–∏–∏.
        
        Args:
            download_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∫–∞—á–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            
        Returns:
            dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∫–∞—á–∞–Ω–Ω–æ–º –±—ç–∫–∞–ø–µ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if not self.enabled:
            noFapLogger.warning("S3 backup is disabled, cannot download")
            return {}
            
        try:
            latest_key = "database_backups/all_scores_saved_latest.json"
            
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–∞
            head_response = self.s3_client.head_object(
                Bucket=self.bucket_name,
                Key=latest_key
            )
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            self.s3_client.download_file(
                self.bucket_name,
                latest_key,
                download_path
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –¥–ª—è —Ä–µ–≤–∏–∑–∏–∏
            backup_info = {
                'source': 'S3',
                'key': latest_key,
                'size': head_response['ContentLength'],
                'last_modified': head_response['LastModified'],
                'etag': head_response['ETag'].strip('"'),
                'download_path': download_path
            }
            
            # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            try:
                with open(download_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    backup_info['users_count'] = len(data) if isinstance(data, dict) else 0
                    backup_info['content_preview'] = str(data)[:200] + "..." if len(str(data)) > 200 else str(data)
            except Exception as e:
                noFapLogger.error(f"Could not read backup content for stats: {e}")
                backup_info['users_count'] = 'unknown'
                backup_info['content_preview'] = 'unavailable'
            
            noFapLogger.info(f"Latest backup downloaded from S3 to: {download_path}")
            return backup_info
            
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'NoSuchKey':
                noFapLogger.error("No backup found in S3")
            else:
                noFapLogger.error(f"S3 ClientError during download: {e}")
            return {}
            
        except Exception as e:
            noFapLogger.error(f"Unexpected error during S3 download: {e}")
            return {}
    
    def list_backups(self) -> list:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤ –≤ S3.
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –±—ç–∫–∞–ø–æ–≤
        """
        if not self.enabled:
            return []
            
        try:
            response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix="database_backups/"
            )
            
            if 'Contents' in response:
                backups = []
                for obj in response['Contents']:
                    backups.append({
                        'key': obj['Key'],
                        'size': obj['Size'],
                        'last_modified': obj['LastModified']
                    })
                return sorted(backups, key=lambda x: x['last_modified'], reverse=True)
            
            return []
            
        except Exception as e:
            noFapLogger.error(f"Error listing S3 backups: {e}")
            return []
    
    def upload_folder_as_zip(self, folder_path: str, s3_key: str) -> dict:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞–ø–∫—É –≤ S3 –∫–∞–∫ ZIP –∞—Ä—Ö–∏–≤.
        
        Args:
            folder_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è
            s3_key: –ö–ª—é—á –≤ S3 –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–∞
            
        Returns:
            dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º –∞—Ä—Ö–∏–≤–µ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if not self.enabled:
            noFapLogger.warning("S3 backup is disabled, cannot upload folder")
            return {}
            
        if not os.path.exists(folder_path):
            noFapLogger.error(f"Folder not found: {folder_path}")
            return {}
            
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π ZIP —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as temp_zip:
                temp_zip_path = temp_zip.name
            
            # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –ø–∞–ø–∫—É
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(folder_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –≤ –∞—Ä—Ö–∏–≤–µ
                        arcname = os.path.relpath(file_path, folder_path)
                        zipf.write(file_path, arcname)
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–∑–¥–∞–Ω–Ω–æ–º –∞—Ä—Ö–∏–≤–µ
            zip_size = os.path.getsize(temp_zip_path)
            files_count = len([f for _, _, files in os.walk(folder_path) for f in files])
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3
            self.s3_client.upload_file(temp_zip_path, self.bucket_name, s3_key)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(temp_zip_path)
            
            upload_info = {
                'source_folder': folder_path,
                's3_key': s3_key,
                'zip_size': zip_size,
                'files_count': files_count,
                'upload_time': datetime.now()
            }
            
            noFapLogger.info(f"Folder uploaded to S3: {s3_key} ({files_count} files, {zip_size} bytes)")
            return upload_info
            
        except Exception as e:
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if 'temp_zip_path' in locals() and os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            noFapLogger.error(f"Error uploading folder to S3: {e}")
            return {}
    
    def download_and_extract_zip(self, s3_key: str, extract_path: str) -> dict:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç ZIP –∞—Ä—Ö–∏–≤ –∏–∑ S3 –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ.
        
        Args:
            s3_key: –ö–ª—é—á ZIP –∞—Ä—Ö–∏–≤–∞ –≤ S3
            extract_path: –ü—É—Ç—å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            
        Returns:
            dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∫–∞—á–∞–Ω–Ω–æ–º –∞—Ä—Ö–∏–≤–µ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if not self.enabled:
            noFapLogger.warning("S3 backup is disabled, cannot download")
            return {}
            
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as temp_zip:
                temp_zip_path = temp_zip.name
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∞—Ä—Ö–∏–≤ –∏–∑ S3
            self.s3_client.download_file(self.bucket_name, s3_key, temp_zip_path)
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            os.makedirs(extract_path, exist_ok=True)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ö–∏–≤
            with zipfile.ZipFile(temp_zip_path, 'r') as zipf:
                zipf.extractall(extract_path)
                files_count = len(zipf.namelist())
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –∞—Ä—Ö–∏–≤–∞
            zip_size = os.path.getsize(temp_zip_path)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(temp_zip_path)
            
            download_info = {
                's3_key': s3_key,
                'extract_path': extract_path,
                'zip_size': zip_size,
                'files_count': files_count,
                'download_time': datetime.now()
            }
            
            noFapLogger.info(f"Archive downloaded and extracted: {s3_key} -> {extract_path} ({files_count} files)")
            return download_info
            
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == 'NoSuchKey':
                noFapLogger.error(f"Archive not found in S3: {s3_key}")
            else:
                noFapLogger.error(f"S3 ClientError during download: {e}")
            return {}
        except Exception as e:
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if 'temp_zip_path' in locals() and os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            noFapLogger.error(f"Error downloading archive from S3: {e}")
            return {}


# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞
s3_backup_manager = S3BackupManager()


def restore_database_from_s3(database_path: str) -> None:
    """
    –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ S3 —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ä–µ–≤–∏–∑–∏–∏.
    
    Args:
        database_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        
    Raises:
        RuntimeError: –ï—Å–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
    """
    noFapLogger.info("üîÑ Starting database restoration from S3...")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs(os.path.dirname(database_path), exist_ok=True)
    
    backup_info = s3_backup_manager.download_latest_backup(database_path)
    
    if backup_info:
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –ë–î
        noFapLogger.info("=" * 60)
        noFapLogger.info("üìã DATABASE RESTORATION REPORT")
        noFapLogger.info("=" * 60)
        noFapLogger.info(f"üîó Source: {backup_info['source']}")
        noFapLogger.info(f"üóÇÔ∏è  S3 Key: {backup_info['key']}")
        noFapLogger.info(f"üìä File Size: {backup_info['size']} bytes")
        noFapLogger.info(f"‚è∞ Last Modified: {backup_info['last_modified']}")
        noFapLogger.info(f"üîê ETag (Revision): {backup_info['etag']}")
        noFapLogger.info(f"üë• Users Count: {backup_info['users_count']}")
        noFapLogger.info(f"üíæ Restored to: {backup_info['download_path']}")
        noFapLogger.info("=" * 60)
        noFapLogger.info("‚úÖ Database successfully restored from S3 backup!")
    else:
        raise RuntimeError(
            f"‚ùå CRITICAL ERROR: Could not restore database from S3 backup. "
            f"No backup found or S3 is not accessible. "
            f"Please check S3 configuration and ensure backup exists."
        )


def backup_memes_to_s3() -> None:
    """
    –°–æ–∑–¥–∞–µ—Ç –±—ç–∫–∞–ø –ø–∞–ø–∫–∏ —Å –º–µ–º–∞–º–∏ –≤ S3.
    
    Raises:
        RuntimeError: –ï—Å–ª–∏ –±—ç–∫–∞–ø –Ω–µ —É–¥–∞–ª—Å—è
    """
    memes_folder = os.path.join("storage", "memes")
    
    if not os.path.exists(memes_folder):
        raise RuntimeError(f"Memes folder not found: {memes_folder}")
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    s3_key = f"memes_backups/memes_{timestamp}.zip"
    latest_key = "memes_backups/memes_latest.zip"
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—Ä—Ö–∏–≤ —Å –º–µ–º–∞–º–∏
    upload_info = s3_backup_manager.upload_folder_as_zip(memes_folder, s3_key)
    
    if not upload_info:
        raise RuntimeError("Failed to upload memes backup to S3")
    
    # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ latest backup
    latest_info = s3_backup_manager.upload_folder_as_zip(memes_folder, latest_key)
    
    if not latest_info:
        noFapLogger.error("Failed to update latest memes backup")
    else:
        noFapLogger.info(f"Latest memes backup updated: {latest_key}")
    
    # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    noFapLogger.info("=" * 60)
    noFapLogger.info("üì∏ MEMES BACKUP REPORT")
    noFapLogger.info("=" * 60)
    noFapLogger.info(f"üìÅ Source Folder: {upload_info['source_folder']}")
    noFapLogger.info(f"‚òÅÔ∏è S3 Key: {upload_info['s3_key']}")
    noFapLogger.info(f"üìä Archive Size: {upload_info['zip_size']} bytes")
    noFapLogger.info(f"üñºÔ∏è Files Count: {upload_info['files_count']} memes")
    noFapLogger.info(f"‚è∞ Upload Time: {upload_info['upload_time']}")
    noFapLogger.info("=" * 60)
    noFapLogger.info("‚úÖ Memes backup completed successfully!")


def restore_memes_from_s3(memes_folder: str) -> None:
    """
    –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞–ø–∫—É —Å –º–µ–º–∞–º–∏ –∏–∑ S3.
    
    Args:
        memes_folder: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ–º–æ–≤
        
    Raises:
        RuntimeError: –ï—Å–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
    """
    noFapLogger.info("üîÑ Starting memes restoration from S3...")
    
    latest_key = "memes_backups/memes_latest.zip"
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ö–∏–≤
    download_info = s3_backup_manager.download_and_extract_zip(latest_key, memes_folder)
    
    if not download_info:
        raise RuntimeError("Failed to restore memes from S3 backup")
    
    # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    noFapLogger.info("=" * 60)
    noFapLogger.info("üì∏ MEMES RESTORATION REPORT")
    noFapLogger.info("=" * 60)
    noFapLogger.info(f"‚òÅÔ∏è S3 Key: {download_info['s3_key']}")
    noFapLogger.info(f"üìÅ Extract Path: {download_info['extract_path']}")
    noFapLogger.info(f"üìä Archive Size: {download_info['zip_size']} bytes")
    noFapLogger.info(f"üñºÔ∏è Files Count: {download_info['files_count']} memes")
    noFapLogger.info(f"‚è∞ Download Time: {download_info['download_time']}")
    noFapLogger.info("=" * 60)
    noFapLogger.info("‚úÖ Memes successfully restored from S3 backup!")


def backup_database_to_s3():
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ - —Å–æ–∑–¥–∞–µ—Ç –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤ S3.
    """
    database_path = os.path.join("storage", "all_scores_saved.json")
    
    if s3_backup_manager.upload_database_backup(database_path):
        noFapLogger.info("Scheduled database backup to S3 completed successfully")
    else:
        noFapLogger.error("Scheduled database backup to S3 failed")


def backup_all_to_s3():
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ - —Å–æ–∑–¥–∞–µ—Ç –±—ç–∫–∞–ø –ë–î –∏ –º–µ–º–æ–≤ –≤ S3.
    """
    try:
        # –ë—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        backup_database_to_s3()
        
        # –ë—ç–∫–∞–ø –º–µ–º–æ–≤
        backup_memes_to_s3()
        
        noFapLogger.info("üéâ Complete backup (database + memes) to S3 completed successfully!")
        
    except Exception as e:
        noFapLogger.error(f"Complete backup to S3 failed: {e}")
